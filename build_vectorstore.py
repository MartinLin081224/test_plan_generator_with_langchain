import os
import shutil
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import (
    PyMuPDFLoader,
    UnstructuredWordDocumentLoader,
    TextLoader,
    UnstructuredMarkdownLoader,
    UnstructuredImageLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter

input_dir = "input"
docs = []

print("ğŸ“ æƒæ input è³‡æ–™å¤¾...")
input_files = os.listdir(input_dir)
if not input_files:
    print("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½• input æ–‡ä»¶ï¼Œè«‹ç¢ºèª input è³‡æ–™å¤¾ä¸ç‚ºç©º")
else:
    for file in input_files:
        print(f"ğŸ”¹ ç™¼ç¾æª”æ¡ˆï¼š{file}")

# æ¯æ¬¡é‡æ–°å»ºåº«å‰ï¼Œåˆªé™¤ chroma_db ç›®éŒ„ï¼ˆåŠ ä¸Šå®¹éŒ¯è™•ç†ï¼‰
if os.path.exists("chroma_db"):
    try:
        shutil.rmtree("chroma_db")
        print("ğŸ§¹ å·²æ¸…ç©ºèˆŠçš„ chroma_db è³‡æ–™å¤¾")
    except PermissionError:
        print("âŒ chroma_db æ­£åœ¨è¢«ä½”ç”¨ï¼Œè«‹å…ˆé—œé–‰ Streamlit æˆ–å…¶ä»–æ‡‰ç”¨ç¨‹å¼å†é‡è©¦")
        exit()

# è¼‰å…¥æ–‡ä»¶
for file in input_files:
    path = os.path.join(input_dir, file)
    try:
        if file.endswith(".pdf"):
            loader = PyMuPDFLoader(path)
        elif file.endswith(".docx"):
            loader = UnstructuredWordDocumentLoader(path)
        elif file.endswith(".txt") or file.endswith(".yaml") or file.endswith(".yml"):
            loader = TextLoader(path, encoding="utf-8")
        elif file.endswith(".md"):
            loader = UnstructuredMarkdownLoader(path)
        elif file.endswith((".png", ".jpg", ".jpeg")):
            loader = UnstructuredImageLoader(path)
        else:
            print(f"âš ï¸ è·³éä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹ï¼š{file}")
            continue

        file_docs = loader.load()
        print(f"âœ… æˆåŠŸè¼‰å…¥ï¼š{file}ï¼ˆå…± {len(file_docs)} ç­†ï¼‰")
        docs.extend(file_docs)

    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•—ï¼š{file}ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{str(e)}")

# åˆ†æ®µ
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
chunks = splitter.split_documents(docs)

if not chunks:
    print("âŒ ç„¡æœ‰æ•ˆå…§å®¹å¯å»ºç«‹å‘é‡åº«ï¼Œè«‹ç¢ºèªæ–‡ä»¶å…§å®¹æ ¼å¼")
    exit()

# åµŒå…¥å‘é‡ä¸¦å»ºç«‹ Chroma è³‡æ–™åº«
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = Chroma.from_documents(chunks, embedding=embedding, persist_directory="chroma_db")

print(f"ğŸ“„ ç¸½æ–‡ä»¶æ•¸ï¼š{len(docs)}ï¼Œåˆ†æ®µå¾Œå…±ï¼š{len(chunks)}")
print("âœ… å‘é‡è³‡æ–™åº«å·²å»ºç«‹ä¸¦å„²å­˜åœ¨ chroma_db/")
